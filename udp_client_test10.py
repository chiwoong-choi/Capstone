#í‹€ë¦°ê±° ê²½ê³  ì¶”ê°€
#ìˆ˜ì • ë‚´ìš©: generate_silhouette()í•¨ìˆ˜ì—ì„œ í¸ì…ëœ í”½ì…€ì˜ ì¢Œí‘œë¥¼ npyíŒŒì¼ë¡œ ì €ì¥
#ì €ì¥ëœ íŒŒì¼ì„ realtime_synchronize()í•¨ìˆ˜ì—ì„œ ë¶ˆëŸ¬ì™€ì„œ ì‚¬ìš©
#ëœë“œë§ˆí¬ ê±°ë¦¬ì— ë”°ë¼ ì‹¤ë£¨ì—£ê³¼ì˜ ì°¨ì´ ê³„ì‚° ë° ìƒ‰ìƒ ê²½ê³  ì¶”ê°€
#ìˆ˜ì • í•„ìš” ì‚¬í•­: mediapipe ì—°ì‚°ì„ ìœ„í•œ íƒ€ì„ìŠ¤íƒ¬í”„ -> realtime_synchronizeí•¨ìˆ˜ì˜ poseê°ì²´ ì£¼ê¸°ì  ì´ˆê¸°í™”
import cv2
import os
import time
import csv
import numpy as np
import socket
from flask import Flask, render_template, send_from_directory, Response, request, redirect, url_for, abort
from threading import Thread, Lock
import mediapipe as mp
import struct
import subprocess
import random
from concurrent.futures import ThreadPoolExecutor

executor = ThreadPoolExecutor(max_workers=2)

#ffmpeg ì¸ì½”ë”©ë²„ì „

# ------------------- UDPFrameReceiver í´ë˜ìŠ¤ -------------------
import threading

class TCPFrameReceiver:
    def __init__(self, tcp_ip, tcp_port):
        """
        TCP ì†Œì¼“ì„ í†µí•´ í”„ë ˆì„ì„ ìˆ˜ì‹ í•˜ëŠ” í´ë˜ìŠ¤.
        
        Args:
            tcp_ip (str): ìˆ˜ì‹ í•  IP ì£¼ì†Œ.
            tcp_port (int): ìˆ˜ì‹ í•  í¬íŠ¸ ë²ˆí˜¸.
        """
        self.tcp_ip = tcp_ip
        self.tcp_port = tcp_port
        self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.socket.bind((tcp_ip, tcp_port))
        self.socket.listen(1)  # í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ëŒ€ê¸°
        print(f"âœ… [INFO] TCP ì„œë²„ê°€ {tcp_ip}:{tcp_port}ì—ì„œ ëŒ€ê¸° ì¤‘ì…ë‹ˆë‹¤...")
        
        self.conn, self.addr = self.socket.accept()  # í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ìˆ˜ë½
        print(f"âœ… [INFO] í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ìˆ˜ë½: {self.addr}")
        
        self.running = True
        self.frame = None
        #self.timestamp = None
        self.lock = threading.Lock()
        self.thread = threading.Thread(target=self.update, daemon=True)
        self.thread.start()

    def update(self):
        """
        TCP ì†Œì¼“ì„ í†µí•´ ì§€ì†ì ìœ¼ë¡œ í”„ë ˆì„ì„ ìˆ˜ì‹ í•˜ëŠ” ë©”ì„œë“œ.
        """
        while self.running:
            try:
                
                # ë°ì´í„° í¬ê¸° í—¤ë”(4ë°”ì´íŠ¸) ìˆ˜ì‹ 
                header = self.conn.recv(12)
                
                if not header:
                    print("âš ï¸ [WARNING] í—¤ë”ë¥¼ ìˆ˜ì‹ í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì—°ê²°ì´ ì¢…ë£Œë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    break
                timestamp, size = struct.unpack("QI", header)

                # í”„ë ˆì„ ë°ì´í„° ìˆ˜ì‹ 
                data = b""
                while len(data) < size:
                    packet = self.conn.recv(size - len(data))
                    if not packet:
                        print("âš ï¸ [WARNING] ë°ì´í„° ìˆ˜ì‹  ì¤‘ ì—°ê²°ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                        break
                    data += packet

                # í”„ë ˆì„ ë””ì½”ë”©
                frame = cv2.imdecode(np.frombuffer(data, np.uint8), cv2.IMREAD_COLOR)
                if frame is not None:
                    with self.lock:
                        if hasattr(self, 'timestamp') and self.timestamp is not None:
                            if timestamp <= self.timestamp:
                                #print(f"âš ï¸ [WARNING] ì—­ì „ëœ timestamp í”„ë ˆì„ ë¬´ì‹œ: {timestamp} <= {self.timestamp}")
                                continue
                        self.frame = frame
                        self.timestamp = timestamp
                        #print("âœ… [INFO] í”„ë ˆì„ ìˆ˜ì‹  ë° ë””ì½”ë”© ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ [WARNING] í”„ë ˆì„ ìˆ˜ì‹  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                break

    def get_frame(self):
        """
        ìµœì‹  í”„ë ˆì„ì„ ë°˜í™˜í•˜ëŠ” ë©”ì„œë“œ.
        
        Returns:
            np.ndarray: ìµœì‹  í”„ë ˆì„ (ì—†ìœ¼ë©´ None).
        """
        with self.lock:
            if self.frame is None:
                print("âš ï¸ [WARNING] í”„ë ˆì„ì´ Noneì…ë‹ˆë‹¤. ë°ì´í„°ë¥¼ ìˆ˜ì‹ í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return None, None
        return self.frame.copy(), self.timestamp

    def stop(self):
        """
        ìˆ˜ì‹ ì„ ì¤‘ì§€í•˜ê³  ì†Œì¼“ ë° ìŠ¤ë ˆë“œë¥¼ ì •ë¦¬í•˜ëŠ” ë©”ì„œë“œ.
        """
        self.running = False
        self.thread.join()
        self.conn.close()
        self.socket.close()
        print("ğŸ”´ [INFO] TCP ì„œë²„ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

# ------------------- ë™ê¸°í™” í•¨ìˆ˜ -------------------
def get_synchronized_frames(front_camera, right_camera, max_time_diff=200000):
    """
    ë‘ ì¹´ë©”ë¼ì˜ ìµœì‹  í”„ë ˆì„ì„ ë™ê¸°í™”í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        front_camera (TCPFrameReceiver): ì „ë©´ ì¹´ë©”ë¼ ìˆ˜ì‹ ê¸°.
        right_camera (TCPFrameReceiver): ì¸¡ë©´ ì¹´ë©”ë¼ ìˆ˜ì‹ ê¸°.
        max_time_diff (int): ë‘ í”„ë ˆì„ì˜ íƒ€ì„ìŠ¤íƒ¬í”„ ì°¨ì´ í—ˆìš© ë²”ìœ„ (ë§ˆì´í¬ë¡œì´ˆ ë‹¨ìœ„).
    
    Returns:
        tuple: ë™ê¸°í™”ëœ ì „ë©´ ë° ì¸¡ë©´ í”„ë ˆì„ (ì—†ìœ¼ë©´ None, None).
    """
    front_frame, front_timestamp = front_camera.get_frame()
    right_frame, right_timestamp = right_camera.get_frame()

    if front_frame is None or right_frame is None:
        print("âš ï¸ [WARNING] ë™ê¸°í™”ëœ í”„ë ˆì„ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, None

    # íƒ€ì„ìŠ¤íƒ¬í”„ ì°¨ì´ ê³„ì‚°
    time_diff = abs(front_timestamp - right_timestamp)
    if time_diff > max_time_diff:
        print(f"âš ï¸ [WARNING] íƒ€ì„ìŠ¤íƒ¬í”„ ì°¨ì´ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤: {time_diff}Î¼s")
        return None, None

    return front_frame, right_frame

# ------------------- MediaPipe ì´ˆê¸°í™” -------------------
mp_pose = mp.solutions.pose
pose = mp_pose.Pose(
    static_image_mode=False,
    model_complexity=0,
    smooth_landmarks=True,
    min_detection_confidence=0.3,
    min_tracking_confidence=0.3
)

# ------------------- ê²½ë¡œ ë³€ìˆ˜ ì„ ì–¸ -------------------
front_save_image_dir = "front_squat_frames"
right_save_image_dir = "right_squat_frames"
front_input_dir = "./front_squat_frames"
right_input_dir = "./right_squat_frames"
front_silhouette_dir = "./front_silhouette"
right_silhouette_dir = "./right_silhouette"
data_dict = {} 

os.makedirs(front_save_image_dir, exist_ok=True)
os.makedirs(right_save_image_dir, exist_ok=True)

result_save_image_dir = "frames"
front_result_output_video_path = "front_result.mp4"
right_result_output_video_path = "right_result.mp4"

streaming_flags = {0: False, 1: False}
# ------------------- í¬ì¦ˆ ë¶„ì„ í•¨ìˆ˜ -------------------

#ì‹œì—°ìš© í´ë” ì‚­ì œ í•¨ìˆ˜
def clear_folders(*folders):
    """
    ì§€ì •ëœ í´ë”ì˜ ëª¨ë“  íŒŒì¼ì„ ì‚­ì œí•©ë‹ˆë‹¤.
    í´ë” ìì²´ëŠ” ìœ ì§€ë©ë‹ˆë‹¤.
    
    Args:
        *folders: ì‚­ì œí•  íŒŒì¼ì´ ìˆëŠ” í´ë” ê²½ë¡œë“¤
    """
    for folder in folders:
        if os.path.exists(folder):
            for file_name in os.listdir(folder):
                file_path = os.path.join(folder, file_name)
                try:
                    if os.path.isfile(file_path) or os.path.islink(file_path):
                        os.unlink(file_path)  # íŒŒì¼ ë˜ëŠ” ì‹¬ë³¼ë¦­ ë§í¬ ì‚­ì œ
                    elif os.path.isdir(file_path):
                        os.rmdir(file_path)  # ë¹ˆ ë””ë ‰í† ë¦¬ ì‚­ì œ
                except Exception as e:
                    print(f"âŒ [ERROR] íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {file_path}, {e}")
            print(f"âœ… [INFO] í´ë” ì •ë¦¬ ì™„ë£Œ: {folder}")
        else:
            print(f"âš ï¸ [WARNING] í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {folder}")

# ë‹¤ë¦¬ ê°ë„ ê³„ì‚° í•¨ìˆ˜
def calculate_angle_knee(a, b, c):
    """ì„¸ ì ì„ ì´ìš©í•´ ë¬´ë¦ ê°ë„ë¥¼ ê³„ì‚°"""
    vector_ab = np.array([a[0] - b[0], a[1] - b[1]])  # ë²¡í„° a -> b
    vector_bc = np.array([c[0] - b[0], c[1] - b[1]])  # ë²¡í„° b -> c
    dot_product = np.dot(vector_ab, vector_bc)
    magnitude_ab = np.linalg.norm(vector_ab)
    magnitude_bc = np.linalg.norm(vector_bc)
    cos_angle = dot_product / (magnitude_ab * magnitude_bc)
    angle = np.degrees(np.arccos(np.clip(cos_angle, -1.0, 1.0)))
    return angle

# ê³¨ë°˜ ê¸°ìš¸ê¸° ê³„ì‚° í•¨ìˆ˜
def calculate_tilt_hip(hip_left, hip_right):
    hip_vect = np.array([hip_right[0] - hip_left[0], hip_right[1]-hip_left[1]])
    ground_vect = np.array([1, 0])  # ì§€ë©´ ê¸°ì¤€ ë²¡í„°
    dot_product_hip = np.dot(hip_vect, ground_vect)
    magnitude_hip_vect = np.linalg.norm(hip_vect)
    cos_hip = dot_product_hip / magnitude_hip_vect
    angle_hip = np.degrees(np.arccos(np.clip(cos_hip, -1.0, 1.0)))
    return angle_hip

# ì–´ê¹¨ ê¸°ìš¸ê¸° ê³„ì‚° í•¨ìˆ˜
def calculate_tilt_shoulder(shoulder_left, shoulder_right):
    """ì–´ê¹¨ì˜ ê¸°ìš¸ê¸° ê°ë„ë¥¼ ê³„ì‚°"""
    shoulder_vect = np.array([shoulder_right[0] - shoulder_left[0], shoulder_right[1] - shoulder_left[1]])
    ground_vect = np.array([1, 0])  # ì§€ë©´ ê¸°ì¤€ ë²¡í„°
    dot_product_shoulder = np.dot(shoulder_vect, ground_vect)
    magnitude_shoulder_vect = np.linalg.norm(shoulder_vect)
    cos_shoulder = dot_product_shoulder / magnitude_shoulder_vect
    angle_shoulder = np.degrees(np.arccos(np.clip(cos_shoulder, -1.0, 1.0)))
    return angle_shoulder

# ë¬´ë¦ ê±°ë¦¬ ê³„ì‚° í•¨ìˆ˜
def calculate_knee_dis(knee_left, knee_right):
    dis_knee = np.abs(knee_left[0] - knee_right[0])
    return dis_knee

# ì–´ê¹¨ ê±°ë¦¬ ê³„ì‚° í•¨ìˆ˜
def calculate_shoulder_dis(shoulder_left, shoulder_right):
    dis_shoulder= np.abs(shoulder_left[0] - shoulder_right[0])
    return dis_shoulder        
        
# ------------------- ëª¨ë²”ìì„¸ ì €ì¥ ìë£Œ ìƒì„±  -------------------

def recording_pose(front_camera, right_camera):
    """5ì´ˆ ë™ì•ˆ í”„ë ˆì„ì„ ì €ì¥"""
    front_frame_count = 0
    right_frame_count = 0
    recording_start_time = time.time()
    frame_index = 0  # ì „ì²´ í”„ë ˆì„ ì¸ë±ìŠ¤
    
    while time.time() - recording_start_time < 5:  # 5ì´ˆ ë™ì•ˆ ë…¹í™”
        front_frame, right_frame = get_synchronized_frames(front_camera, right_camera)
        
        if front_frame is None or right_frame is None:
            print("âš ï¸ [WARNING] ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê³„ì† ì‹œë„ ì¤‘...")
            time.sleep(0.1)  # ì ì‹œ ëŒ€ê¸° í›„ ë‹¤ì‹œ ì‹œë„
            continue
        if frame_index % 2 == 0:
            front_frame_filename = os.path.join(front_save_image_dir, f"{front_frame_count:04d}.png")
            right_frame_filename = os.path.join(right_save_image_dir, f"{right_frame_count:04d}.png")
            cv2.imwrite(front_frame_filename, front_frame)  # ì´ë¯¸ì§€ ì €ì¥
            cv2.imwrite(right_frame_filename, right_frame)
            front_frame_count += 1
            right_frame_count += 1
        frame_index += 1

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    print("ë…¹í™” ì™„ë£Œ. í”„ë ˆì„ ì €ì¥ ì™„ë£Œ.")


def mk_dictionary(csv_file="squat_analysis.csv"):
    global data_dict
    data_dict = {}  # CSV -> ë©”ëª¨ë¦¬ ì €ì¥ìš©
    with open(csv_file, mode="r") as file:
        reader = csv.reader(file)
        next(reader)  # í—¤ë” ê±´ë„ˆë›°ê¸°
        
        for row in reader:
            frame_file, knee_dist, shoulder_tilt, knee_angle, hip_tilt, shoulder_distance = row
            knee_dist = float(knee_dist)
            shoulder_tilt = float(shoulder_tilt)
            knee_angle = float(knee_angle)
            hip_tilt = float(hip_tilt)
            shoulder_distance = float(shoulder_distance)
            data_dict[frame_file] = (knee_dist, shoulder_tilt, knee_angle, hip_tilt, shoulder_distance)
    
    return data_dict

# ------------------- ëª¨ë²”ìì„¸ ë¶„ì„ -------------------

def analyse_pose():
    """ì €ì¥ëœ í”„ë ˆì„ì„ ë¶ˆëŸ¬ì™€ ë¬´ë¦ ê°ë„ì™€ ì–´ê¹¨ ê¸°ìš¸ê¸°ë¥¼ ë¶„ì„í•˜ê³  ê²°ê³¼ë¥¼ ì¦‰ì‹œ ì €ì¥"""
    # CSV íŒŒì¼ë¡œ ê²°ê³¼ ì €ì¥
    with open("squat_analysis.csv", mode="w", newline='') as file:
        writer = csv.writer(file)
        writer.writerow(["Frame File", "Knee Distance", "Shoulder Tilt", "Knee Angle","Hip Tilt"])  # CSV í—¤ë”

        front_frame_files = sorted(os.listdir(front_save_image_dir))  # ì •ë ¬í•˜ì—¬ ìˆœì„œëŒ€ë¡œ ë¶„ì„

        for frame_file in front_frame_files:
            frame_path = os.path.join(front_save_image_dir, frame_file)
            frame = cv2.imread(frame_path)

            if frame is None:
                continue

            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = pose.process(rgb_frame)

            if results.pose_landmarks:
                landmarks = results.pose_landmarks.landmark

                # ì¢Œí‘œ ì¶”ì¶œ
                hip_left = (landmarks[mp_pose.PoseLandmark.LEFT_HIP].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP].y)
                hip_right = (landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y)
                knee_left = (landmarks[mp_pose.PoseLandmark.LEFT_KNEE].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE].y)
                knee_right = (landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].x, landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].y)
                ankle_left = (landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].x, landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].y)
                shoulder_left = (landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y)
                shoulder_right = (landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].y)

                # ê°ë„ ê³„ì‚°
                knee_angle = calculate_angle_knee(hip_left, knee_left, ankle_left)
                shoulder_tilt = calculate_tilt_shoulder(shoulder_left, shoulder_right)
                knee_distance = calculate_knee_dis(knee_left, knee_right)
                hip_tilt = calculate_tilt_hip(hip_left, hip_right)
                shoulder_distance = calculate_shoulder_dis(shoulder_right, shoulder_left)
                # ë¶„ì„ ê²°ê³¼ë¥¼ CSVì— ì €ì¥
                writer.writerow([frame_file, knee_distance, shoulder_tilt, knee_angle, hip_tilt,shoulder_distance])
                print(f"{frame_file}: Knee Distance = {knee_distance:.2f}, Shoulder Tilt = {shoulder_tilt:.2f}, Knee_angle = {knee_angle:.2f}, Hip_Tilt = {hip_tilt:.2f}, Shoulder_Distance = {shoulder_distance:.2f}")
                

    print("ê°ë„ ë¶„ì„ ì™„ë£Œ. ê²°ê³¼ ì €ì¥ë¨: squat_analysis.csv")
    
def control_squat_posture(data_dict):
    not_deep_squat = False
    st_failed_front_frame_num = [] # ìì„¸ê°€ ì˜ëª»ëœ frame ì €ì¥ìš©
    ht_failed_front_frame_num = []
    kd_failed_front_frame_num = []
    min_knee_angle = min(value[2] for value in data_dict.values())
    min_angle_frame = min(data_dict, key=lambda k: data_dict[k][2])
    print(f"frame-{min_angle_frame} has min_angle: {min_knee_angle:.2f}")
    
    max_shoulder_distance = max(value[4] for value in data_dict.values())
    print(f"{max_shoulder_distance}")
    half_shoulder_distance = 0.5*max_shoulder_distance
    print(f"{half_shoulder_distance}")

    # ìŠ¤ì¿¼íŠ¸ ê°ë„ 
    if min_knee_angle > 80:
        print("Not Deep Squat")
        not_deep_squat = True
        
    # ê¸°íƒ€ ê°ë„ ì—°ì‚° 
    for frame_file, (knee_dist, shoulder_tilt, knee_angle, hip_tilt,shoulder_distance) in data_dict.items():
        #ì–´ê¹¨ ë¶ˆê· í˜•ì„ ë°”ë¡œ ê³ ì§€í•¨
        if shoulder_tilt < 177:
            print("Shoulder Tilted")
            st_failed_front_frame_num.append(frame_file) #ìì„¸ê°€ ì˜ëª»ëœ í”„ë ˆì„ ë²ˆí˜¸ ì €ì¥
            
        if hip_tilt < 177:
            print("Hip Tilted")
            ht_failed_front_frame_num.append(frame_file) #ìì„¸ê°€ ì˜ëª»ëœ í”„ë ˆì„ ë²ˆí˜¸ ì €ì¥
         
        if knee_dist > 1.2*max_shoulder_distance:
            print("Knee So Far")
            kd_failed_front_frame_num.append(frame_file) #ìì„¸ê°€ ì˜ëª»ëœ í”„ë ˆì„ ë²ˆí˜¸ ì €ì¥  
            
        if knee_dist < half_shoulder_distance:
            print("Knee So Close")
            kd_failed_front_frame_num.append(frame_file) #ìì„¸ê°€ ì˜ëª»ëœ í”„ë ˆì„ ë²ˆí˜¸ ì €ì¥
            
    #failed_front_frame_num = list(set(failed_front_frame_num))        
    
    unique_st_failed_front_frame_num = list(dict.fromkeys(st_failed_front_frame_num))
    unique_ht_failed_front_frame_num = list(dict.fromkeys(ht_failed_front_frame_num))
    unique_kd_failed_front_frame_num = list(dict.fromkeys(kd_failed_front_frame_num))
    print(f"{unique_st_failed_front_frame_num}") #ë¦¬ìŠ¤íŠ¸ í™•ì¸ìš©
    print(f"{unique_ht_failed_front_frame_num}") #ë¦¬ìŠ¤íŠ¸ í™•ì¸ìš©
    print(f"{unique_kd_failed_front_frame_num}") #ë¦¬ìŠ¤íŠ¸ í™•ì¸ìš©
    
    
    
    
    return (unique_st_failed_front_frame_num, 
            unique_ht_failed_front_frame_num, 
            unique_kd_failed_front_frame_num, 
            min_angle_frame
            )

def show_result(unique_st_failed_front_frame_num, unique_ht_failed_front_frame_num, unique_kd_failed_front_frame_num, min_angle_frame):
    front_frame_files = sorted(os.listdir(front_save_image_dir))  # ì •ë ¬í•˜ì—¬ ìˆœì„œëŒ€ë¡œ ì¬ìƒ
    right_frame_files = sorted(os.listdir(right_save_image_dir))
    
    st_length = len(unique_st_failed_front_frame_num)
    ht_length = len(unique_ht_failed_front_frame_num)
    kd_length = len(unique_kd_failed_front_frame_num)
    
    total_frames = len(front_frame_files)  # ì´ í”„ë ˆì„ ìˆ˜
    
    st_accuracy = (total_frames - st_length) / total_frames * 100
    ht_accuracy = (total_frames - ht_length) / total_frames * 100
    kd_accuracy = (total_frames - kd_length) / total_frames * 100
    
    # ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
    result_save_dir = "static"
    os.makedirs(result_save_dir, exist_ok=True)
    
    # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„± (FFmpeg ì…ë ¥ìš©)
    temp_front_dir = os.path.join(result_save_dir, "temp_front")
    temp_right_dir = os.path.join(result_save_dir, "temp_right")
    os.makedirs(temp_front_dir, exist_ok=True)
    os.makedirs(temp_right_dir, exist_ok=True)

    # í”„ë ˆì„ ì²˜ë¦¬ ë° ì €ì¥
    for i, frame_file in enumerate(front_frame_files):
        front_frame_path = os.path.join(front_save_image_dir, frame_file)
        right_frame_path = os.path.join(right_save_image_dir, frame_file)
        front_frame = cv2.imread(front_frame_path)
        right_frame = cv2.imread(right_frame_path)

        if front_frame is None or right_frame is None:
            print(f"âš ï¸ [WARNING] Frame {frame_file} is None. Skipping...")
            continue

        # ğŸ”¹ í‹€ë¦° í”„ë ˆì„ ê°•ì¡° ë° ëœë“œë§ˆí¬ í‘œì‹œ
        rgb_front_frame = cv2.cvtColor(front_frame, cv2.COLOR_BGR2RGB)
        front_results = pose.process(rgb_front_frame)
        rgb_right_frame = cv2.cvtColor(right_frame, cv2.COLOR_BGR2RGB)
        right_results = pose.process(rgb_right_frame)
        
        if front_results.pose_landmarks:
            landmarks = front_results.pose_landmarks.landmark
            front_height, front_width, _ = front_frame.shape

            # ëœë“œë§ˆí¬ ì¢Œí‘œ ê³„ì‚°
            shoulder_left = (int(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x * front_width),
                             int(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y * front_height))
            shoulder_right = (int(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * front_width),
                              int(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * front_height))
            hip_left = (int(landmarks[mp_pose.PoseLandmark.LEFT_HIP].x * front_width),
                        int(landmarks[mp_pose.PoseLandmark.LEFT_HIP].y * front_height))
            hip_right = (int(landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x * front_width),
                         int(landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y * front_height))
            knee_left = (int(landmarks[mp_pose.PoseLandmark.LEFT_KNEE].x * front_width),
                         int(landmarks[mp_pose.PoseLandmark.LEFT_KNEE].y * front_height))
            knee_right = (int(landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].x * front_width),
                          int(landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].y * front_height))
            

            # í‹€ë¦° í”„ë ˆì„ ê°•ì¡°
            if frame_file in unique_st_failed_front_frame_num:
                cv2.line(front_frame, shoulder_left, shoulder_right, (0, 0, 255), 3)  # ì–´ê¹¨ ë¹¨ê°„ì„ 
            if frame_file in unique_ht_failed_front_frame_num:
                cv2.line(front_frame, hip_left, hip_right, (0, 0, 255), 3)  # ê³¨ë°˜ ë¹¨ê°„ì„ 
            if frame_file in unique_kd_failed_front_frame_num:
                cv2.line(front_frame, knee_left, knee_right, (0, 0, 255), 3)  # ë¬´ë¦ ë¹¨ê°„ì„ 
        # ì„ì‹œ ë””ë ‰í† ë¦¬ì— í”„ë ˆì„ ì €ì¥
        front_temp_path = os.path.join(temp_front_dir, f"{i:04d}.png")
        right_temp_path = os.path.join(temp_right_dir, f"{i:04d}.png")
        cv2.imwrite(front_temp_path, front_frame)
        cv2.imwrite(right_temp_path, right_frame)

    # FFmpeg ëª…ë ¹ì–´ë¡œ MP4 íŒŒì¼ ìƒì„±
    front_result_output_video_path = os.path.join(result_save_dir, "front_result.mp4")
    right_result_output_video_path = os.path.join(result_save_dir, "right_result.mp4")

    ffmpeg_front_command = [
        "ffmpeg", "-y", "-framerate", "20", "-i", os.path.join(temp_front_dir, "%04d.png"),
        "-c:v", "libx264", "-pix_fmt", "yuv420p", front_result_output_video_path
    ]
    ffmpeg_right_command = [
        "ffmpeg", "-y", "-framerate", "20", "-i", os.path.join(temp_right_dir, "%04d.png"),
        "-c:v", "libx264", "-pix_fmt", "yuv420p", right_result_output_video_path
    ]

    # FFmpeg ì‹¤í–‰
    subprocess.run(ffmpeg_front_command, check=True)
    subprocess.run(ffmpeg_right_command, check=True)

    # ì„ì‹œ ë””ë ‰í† ë¦¬ ì‚­ì œ
    for temp_dir in [temp_front_dir, temp_right_dir]:
        for file_name in os.listdir(temp_dir):
            os.remove(os.path.join(temp_dir, file_name))
        os.rmdir(temp_dir)

    print(f"âœ… [INFO] ê²°ê³¼ ë™ì˜ìƒ ì €ì¥ ì™„ë£Œ: {front_result_output_video_path}, {right_result_output_video_path}")
    return st_accuracy, ht_accuracy, kd_accuracy

# ------------------- ëª¨ë²”ìì„¸ ì‹¤ë£¨ì—£ ìƒì„±  -------------------
def generate_silhouette(input_dir, output_dir, segment, pose, body_parts, colors):
    os.makedirs(output_dir, exist_ok=True)
    image_files = sorted(os.listdir(input_dir))

    for img_name in image_files:
        img_path = os.path.join(input_dir, img_name)
        frame = cv2.imread(img_path)
        if frame is None:
            continue

        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results_segmentation = segment.process(frame_rgb)
        results_pose = pose.process(frame_rgb)

        if not results_pose.pose_landmarks:
            print(f"âš ï¸ [WARNING] ëœë“œë§ˆí¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {img_name}")
            silhouette_frame = np.zeros_like(frame)
            output_path = os.path.join(output_dir, img_name)
            cv2.imwrite(output_path, silhouette_frame)
            continue

        landmarks = results_pose.pose_landmarks.landmark
        height, width, _ = frame.shape
        landmark_points = {
            idx: (int(landmark.x * width), int(landmark.y * height))
            for idx, landmark in enumerate(landmarks) if landmark.visibility > 0.5
        }

        mask = results_segmentation.segmentation_mask
        _, binary_mask = cv2.threshold(mask, 0.5, 255, cv2.THRESH_BINARY)
        binary_mask = binary_mask.astype(np.uint8)

        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))
        binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)

        binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)
        
        contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
##
        silhouette_frame = np.zeros_like(frame)
        cv2.drawContours(silhouette_frame, contours, -1, (255, 0, 0), thickness=5)  # ë¹¨ê°„ìƒ‰ ì™¸ê³½ì„ 
        
        assignments = {part: [] for part in body_parts}

        for contour in contours:
            if contour.ndim == 3 and contour.shape[2] == 2:
                contour = contour.squeeze(axis=1)
            elif contour.ndim != 2 or contour.shape[1] != 2:
                print(f"âš ï¸ [WARNING] ì˜ëª»ëœ ì»¨íˆ¬ì–´ í˜•ì‹: {contour.shape}")
                continue

            for pt in contour:
                min_dist = float('inf')
                closest_part = None
                for part, indices in body_parts.items():
                    for idx in indices:
                        if idx in landmark_points:
                            dist = np.linalg.norm(np.array(pt) - np.array(landmark_points[idx]))
                            if dist < min_dist:
                                min_dist = dist
                                closest_part = part
                if closest_part:
                    assignments[closest_part].append(tuple(pt))

        for part, points in assignments.items():
            for pt in points:
                cv2.circle(silhouette_frame, pt, 3, colors[part], -1)
        
        base_name = os.path.splitext(img_name)[0]
        for part, points in assignments.items():
            if not points:
                continue
            part_path = os.path.join(output_dir, f"{base_name}_{part}.npy")
            np.save(part_path, np.array(points))
            
        output_path = os.path.join(output_dir, img_name)
        cv2.imwrite(output_path, silhouette_frame)
        
    print(f"âœ… [INFO] ì‹¤ë£¨ì—£ {len(image_files)}ê°œë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

def create_silhouettes(front_input_dir, right_input_dir, front_silhouette_dir, right_silhouette_dir):
    mp_selfie_segmentation = mp.solutions.selfie_segmentation
    segment = mp_selfie_segmentation.SelfieSegmentation(model_selection=1)

    mp_pose = mp.solutions.pose
    pose = mp_pose.Pose(
        static_image_mode=True,
        model_complexity=2,
        enable_segmentation=False,
        min_detection_confidence=0.5
    )

    body_parts = {
        "head": [0],
        "left_arm": [11, 13, 15],
        "right_arm": [12, 14, 16],
        "left_leg": [23, 25, 27],
        "right_leg": [24, 26, 28]
        #"torso": [11, 12, 23, 24]
    }

    colors = {
        "head": (255, 0, 0),
        "left_arm": (255, 0, 0),
        "right_arm": (255, 0, 0),
        "left_leg": (255, 0, 0),
        "right_leg": (255, 0, 0)
        #"torso": (255, 0, 0)
    }

    # Generate front and right silhouettes
    generate_silhouette(front_input_dir, front_silhouette_dir, segment, pose, body_parts, colors)
    generate_silhouette(right_input_dir, right_silhouette_dir, segment, pose, body_parts, colors)


# ------------------- ì‹¤ì‹œê°„ ì‹¤ë£¨ì—£ ì˜¤ë²„ë ˆì´  -------------------

def process_frame(camera_type, frame, timestamp, pose, silhouette_dir, silhouette_angle, body_parts, colors, previous_knee_angle=None, previous_silhouette=None, angle_threshold=1):
    """
    ë‹¨ì¼ í”„ë ˆì„ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜.
    ì‹¤ë£¨ì—£ ì˜¤ë²„ë ˆì´ ìµœì í™” ë¡œì§ í¬í•¨.
    """
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = pose.process(frame_rgb)#, timestamp=timestamp)

    if not results.pose_landmarks:
        return frame, previous_knee_angle, previous_silhouette  # ëœë“œë§ˆí¬ê°€ ì—†ìœ¼ë©´ ì›ë³¸ í”„ë ˆì„ ë°˜í™˜

    landmarks = results.pose_landmarks.landmark
    height, width, _ = frame.shape

    # ë¬´ë¦ ê°ë„ ê³„ì‚°
    hip = (landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x * width, landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y * height)
    knee = (landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].x * width, landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].y * height)
    ankle = (landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE].x * width, landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE].y * height)
    knee_angle = calculate_angle_knee(hip, knee, ankle)
    
    # ë‹¤ë¦¬ ê°ë„ ë³€í™”ê°€ ê±°ì˜ ì—†ëŠ” ê²½ìš° ì´ì „ ì‹¤ë£¨ì—£ ì‚¬ìš©
    if previous_knee_angle is not None and abs(knee_angle - previous_knee_angle) <= angle_threshold:
        silhouette = previous_silhouette
    else:
        # ì‹¤ë£¨ì—£ ì„ íƒ
        closest_frame_index = np.argmin(np.abs(silhouette_angle - knee_angle))
        silhouette = {}
        for part in body_parts:
            try:
                silhouette[part] = np.load(os.path.join(silhouette_dir, f"{closest_frame_index:04d}_{part}.npy"))
            except Exception as e:
                print(f"âš ï¸ [WARNING] {camera_type} - {part} ì‹¤ë£¨ì—£ ë¡œë“œ ì‹¤íŒ¨: {e}")
                silhouette[part] = []

        # ì´ì „ ì‹¤ë£¨ì—£ ì—…ë°ì´íŠ¸
        previous_silhouette = silhouette

    # ì´ì „ ë‹¤ë¦¬ ê°ë„ ì—…ë°ì´íŠ¸
    previous_knee_angle = knee_angle

    # ì‹¤ë£¨ì—£ ì˜¤ë²„ë ˆì´
    overlay = frame.copy()
    mismatch_parts = []

    for part, indices in body_parts.items():
        try:
            part_pixels = silhouette.get(part, [])
            part_centroid = np.mean(part_pixels, axis=0) if len(part_pixels) > 0 else None
            landmark_centroid = np.mean([(landmarks[i].x * width, landmarks[i].y * height) for i in indices], axis=0)
            if part_centroid is not None and landmark_centroid is not None:
                dist = np.linalg.norm(np.array(part_centroid) - np.array(landmark_centroid))
                if dist > 80:  # ì˜¤ì°¨ í—ˆìš© ê¸°ì¤€(px)
                    mismatch_parts.append(part)
            for pt in part_pixels:
                color = (0, 0, 255) if part in mismatch_parts else colors[part]
                cv2.circle(overlay, tuple(pt), 1, color, -1)
        except Exception as e:
            print(f"âš ï¸ [WARNING] {camera_type} - {part} ì˜¤ë²„ë ˆì´ ì‹¤íŒ¨: {e}")
            continue
        
    
    
    return overlay, previous_knee_angle, previous_silhouette

def realtime_synchronize(camera_type, data_dict, front_camera_thread, right_camera_thread,reps=1, sets=3):
    """
    ì „ë©´ ë° ì¸¡ë©´ ì¹´ë©”ë¼ë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë°.
    """
    print("ğŸ”µ [INFO] ì‹¤ë£¨ì—£ ë™ê¸°í™” ì‹œì‘")

    silhouette_angle = np.array([value[2] for value in data_dict.values()])  # ê° í”„ë ˆì„ì˜ ë¬´ë¦ ê°ë„
    colors = {
        "head": (255, 0, 0),
        "left_arm": (255, 0, 0),
        "right_arm": (255, 0, 0),
        "left_leg": (255, 0, 0),
        "right_leg": (255, 0, 0)
        #torso": (255, 0, 0)
    }
    body_parts = {
        "head": [0],
        "left_arm": [11, 13, 15],
        "right_arm": [12, 14, 16],
        "left_leg": [23, 25, 27],
        "right_leg": [24, 26, 28]
        #"torso": [11, 12, 23, 24]
    }

    mp_pose = mp.solutions.pose
    pose = mp_pose.Pose(
        static_image_mode=False,
        model_complexity=0,
        smooth_landmarks=True,
        min_detection_confidence=0.3,
        min_tracking_confidence=0.3
    )

    # ì‹¤ë£¨ì—£ ì˜¤ë²„ë© ìµœì í™” ë³€ìˆ˜
    previous_knee_angle_front = None
    previous_silhouette_front = None
    previous_knee_angle_right = None
    previous_silhouette_right = None
    squat_count = 0
    is_squatting = False
    sqaut_count_setting = reps
    set_count_setting = sets
    
    while True:
        try:
            if executor._shutdown:
                print("âŒ [ERROR] executorê°€ ì´ë¯¸ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìŠ¤íŠ¸ë¦¼ ì¤‘ë‹¨.")
                break

        
            
            # ì „ë©´ ë° ì¸¡ë©´ í”„ë ˆì„ ê°€ì ¸ì˜¤ê¸°
            front_frame, front_timestamp = front_camera_thread.get_frame()
            right_frame, right_timestamp = right_camera_thread.get_frame()

            if front_frame is None or right_frame is None:
                print("âš ï¸ [WARNING] í”„ë ˆì„ ì—†ìŒ. ì¢…ë£Œ.")
                break

            # ë³‘ë ¬ ì²˜ë¦¬
            future_front = executor.submit(
                process_frame, "front", front_frame, front_timestamp, pose, front_silhouette_dir,
                silhouette_angle, body_parts, colors, previous_knee_angle_front, previous_silhouette_front
            )
            future_right = executor.submit(
                process_frame, "right", right_frame, right_timestamp, pose, right_silhouette_dir,
                silhouette_angle, body_parts, colors, previous_knee_angle_right, previous_silhouette_right
            )

            processed_front, previous_knee_angle_front, previous_silhouette_front = future_front.result()
            processed_right, previous_knee_angle_right, previous_silhouette_right = future_right.result()

            knee_angle = previous_knee_angle_front
            if knee_angle is not None:
                if knee_angle > 140:
                    if is_squatting:
                        squat_count += 1
                        print(f"âœ… [INFO] ìŠ¤ì¿¼íŠ¸ ì¹´ìš´íŠ¸: {squat_count}")
                        is_squatting = False
                elif knee_angle < 100:
                    is_squatting = True
                    
            # ê²°ê³¼ ìŠ¤íŠ¸ë¦¬ë°
            if camera_type == "front":
                _, buffer = cv2.imencode('.jpg', processed_front)
                yield (b'--frame\r\n'
                       b'Content-Type: image/jpeg\r\n\r\n' + buffer.tobytes() + b'\r\n')
                if squat_count >= sqaut_count_setting:
                    print("[INFO] 10íšŒ ì´ìƒ ìŠ¤ì¿¼íŠ¸ ì™„ë£Œ")
                    break
            
            elif camera_type == "right":
                _, buffer = cv2.imencode('.jpg', processed_right)
                yield (b'--frame\r\n'
                       b'Content-Type: image/jpeg\r\n\r\n' + buffer.tobytes() + b'\r\n')
            
                    
            
        except Exception as e:
            print(f"âŒ [ERROR] ì‹¤ì‹œê°„ ë™ê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            continue
    
# ------------------- Flask ì•± ì´ˆê¸°í™” -------------------

app = Flask(__name__, static_folder='static')

# ë™ê¸°í™”ëœ í”„ë ˆì„ ì €ì¥
front_camera = TCPFrameReceiver("0.0.0.0", 5005)  # ì „ë©´ ì¹´ë©”ë¼ í¬íŠ¸
right_camera = TCPFrameReceiver("0.0.0.0", 5006)  # ì¸¡ë©´ ì¹´ë©”ë¼ í¬íŠ¸



# ------------------- Flask ë¼ìš°íŠ¸ -------------------
def generate_stream(camera):
    def generate():
        while True:
            frame_tuple = camera.get_frame()
            if frame_tuple is None or frame_tuple[0] is None:
                print("âš ï¸ [WARNING] í”„ë ˆì„ì´ Noneì…ë‹ˆë‹¤. ê³„ì† ì‹œë„ ì¤‘...")
                time.sleep(0.1)
                continue
            
            frame = frame_tuple[0]  # í”„ë ˆì„ë§Œ ì¶”ì¶œ
            _, buffer = cv2.imencode('.jpg', frame)
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + buffer.tobytes() + b'\r\n')
    return generate

@app.route('/video_feed/front')
def video_feed_front():
    """
    ì „ë©´ ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ì„ ì œê³µí•˜ëŠ” ë¼ìš°íŠ¸.
    """
    return Response(generate_stream(front_camera)(),
                    mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/video_feed/right')
def video_feed_right():
    """
    ì „ë©´ ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ì„ ì œê³µí•˜ëŠ” ë¼ìš°íŠ¸.
    """
    return Response(generate_stream(right_camera)(),
                    mimetype='multipart/x-mixed-replace; boundary=frame')
    
@app.route('/')
def index():
    return render_template('index.html')
    

@app.route('/squat_ex2')
def squat_ex2():
    exercise = request.args.get('exercise', 'default_exercise')
    return render_template('squat_ex2.html', exercise=exercise)

@app.route('/squat_guide3')
def squat_guide3():
    # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹œì‘
    thread = Thread(target=process_squat_analysis, args=(front_camera, right_camera))
    thread.start()
    # ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¼ í˜ì´ì§€ ë Œë”ë§
    return render_template('squat_guide3.html')

pose_analyse_complete = False
silhouette_creation_complete = False
def process_squat_analysis(front_camera, right_camera):
    """
    ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìŠ¤ì¿¼íŠ¸ ë¶„ì„ ì‘ì—…ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜.
    """
    global silhouette_creation_complete
    global pose_analyse_complete
    # 1. í”„ë ˆì„ ì €ì¥
    time.sleep(4) # Nì´ˆ ì¹´ìš´íŠ¸
    recording_pose(front_camera, right_camera)
    
    def run_pose_analyse():
        global pose_analyse_complete
        analyse_pose()
        data_dict = mk_dictionary()
        st_failed, ht_failed, kd_failed, min_angle_frame = control_squat_posture(data_dict)
        show_result(st_failed, ht_failed, kd_failed, min_angle_frame)
        print("âœ… [INFO] ë¶„ì„ ì‘ì—… ì™„ë£Œ. squat_check4.htmlë¡œ ì´ë™í•©ë‹ˆë‹¤.")
        pose_analyse_complete = True
    def run_create_silhouettes():
        global silhouette_creation_complete
        create_silhouettes(front_save_image_dir, right_save_image_dir, front_silhouette_dir, right_silhouette_dir)
        silhouette_creation_complete = True
        print("âœ… [INFO] ì‹¤ë£¨ì—£ ìƒì„± ì™„ë£Œ.")
    Thread(target=run_create_silhouettes).start()
    Thread(target=run_pose_analyse).start()
    
@app.route('/loading')
def loading():
    """
    ë¡œë”© í˜ì´ì§€ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤.
    """
    return render_template('loading.html')
    
@app.route('/squat_check4')
def squat_check4():
    return render_template('squat_check4.html')
    
@app.route('/setting5', methods=['GET', 'POST'])
def setting5():
    if request.method == 'POST':
        print("POST ìš”ì²­ ìˆ˜ì‹ . squat_start6ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸í•©ë‹ˆë‹¤.")
        return redirect(url_for('squat_start6'))
    print("GET ìš”ì²­ ìˆ˜ì‹ . setting5.html ë Œë”ë§í•©ë‹ˆë‹¤.")
    return render_template('setting5.html')

@app.route('/squat_start6')
def squat_start6():
    sets = request.args.get('sets', 3)
    reps = request.args.get('reps', 10)
    return render_template('squat_start6.html', sets=sets, reps=reps)

@app.route('/squat_end7')
def squat_end7():
    accuracy = round(random.uniform(80, 100), 2)  # ë¬´ì‘ìœ„ ì •í™•ë„ ìƒì„±
    feedback = "ë¬´ë¦ì„ ë” ë²Œë¦¬ì„¸ìš”."
    return render_template('squat_end7.html', accuracy=accuracy, feedback=feedback)


@app.route('/silhouette_status')
def silhouette_status():
    """
    ì‹¤ë£¨ì—£ ìƒì„± ìƒíƒœë¥¼ ë°˜í™˜í•˜ëŠ” API.
    """
    global silhouette_creation_complete
    return {'complete': silhouette_creation_complete}

@app.route('/pose_analyse_status')
def psoe_analyse_status():
    """
    ì‹¤ë£¨ì—£ ìƒì„± ìƒíƒœë¥¼ ë°˜í™˜í•˜ëŠ” API.
    """
    global pose_analyse_complete
    return {'complete': pose_analyse_complete}

@app.route('/start_stream/<int:camera_index>')
def start_stream(camera_index):
    """Start streaming for the specified camera index."""
    streaming_flags[camera_index] = True
    return '', 204  # Return a no-content response

@app.route('/stop_stream/<int:camera_index>')
def stop_stream(camera_index):
    """Stop streaming for the specified camera index."""
    streaming_flags[camera_index] = False
    return '', 204  # Return a no-content response

@app.route('/video_feed/overlay/front')
def video_feed_overlay_front():
    reps = int(request.args.get('reps', 10))
    sets = int(request.args.get('sets', 3))
    return Response(realtime_synchronize("front", data_dict, front_camera, right_camera,reps,sets),
                    mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/video_feed/overlay/right')
def video_feed_overlay_right():
    reps = int(request.args.get('reps', 10))
    sets = int(request.args.get('sets', 3))
    return Response(realtime_synchronize("right", data_dict, front_camera, right_camera,reps,sets),
                    mimetype='multipart/x-mixed-replace; boundary=frame')

if __name__ == '__main__':
    try:
        clear_folders(front_save_image_dir, right_save_image_dir, front_silhouette_dir, right_silhouette_dir)
        # Flask ì„œë²„ ì‹¤í–‰
        app.run(host='0.0.0.0', port=5001, threaded=True)
    finally:
        # ìì› ì •ë¦¬
        front_camera.stop()
        right_camera.stop()
        executor.shutdown(wait=True)
