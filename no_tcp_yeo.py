# ìˆ˜ì • í•„ìš” ì‚¬í•­: show_result í™”ë©´ ë¹„ìœ¨ ë§ì¶”ê¸°
# ì¶”ê°€ì‚¬í•­: í˜¹ì‹œëª¨ë¥¼ ì •í™•ë„ í”Œë¡œíŒ…
# ê·¸ ì™¸ ë”°ë¡œ ë¬¸ì œ ì—†ëŠ”ë“¯? í–‰ë³µí•´~~

import cv2
import os
import time
import csv
import numpy as np  
from flask import Flask, render_template, send_from_directory, Response, request, redirect, url_for, abort
from threading import Thread, Lock
import mediapipe as mp
import subprocess
import random
from concurrent.futures import ThreadPoolExecutor
from flask import session
from flask import jsonify
executor = ThreadPoolExecutor(max_workers=4)

#ffmpeg ì¸ì½”ë”©ë²„ì „

# ------------------- -------------------
front_camera = cv2.VideoCapture(0, cv2.CAP_DSHOW)
right_camera = cv2.VideoCapture(1, cv2.CAP_DSHOW)
front_camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
front_camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
right_camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
right_camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

if not front_camera.isOpened() or not right_camera.isOpened():
    print("âš ï¸ [ERROR] ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()


# ------------------- MediaPipe ì´ˆê¸°í™” -------------------
mp_pose = mp.solutions.pose
pose = mp_pose.Pose(
    static_image_mode=False,
    model_complexity=0,
    smooth_landmarks=True,
    min_detection_confidence=0.3,
    min_tracking_confidence=0.3
)

# ------------------- ê²½ë¡œ ë³€ìˆ˜ ì„ ì–¸ -------------------
front_save_image_dir = "front_squat_frames"
right_save_image_dir = "right_squat_frames"
front_input_dir = "./front_squat_frames"
right_input_dir = "./right_squat_frames"
front_silhouette_dir = "./front_silhouette"
right_silhouette_dir = "./right_silhouette"
data_dict = {} 
current_set_status = {}
squat_count_status = {"count": 0, "set": 1}
os.makedirs(front_save_image_dir, exist_ok=True)
os.makedirs(right_save_image_dir, exist_ok=True)
total_frame_count = 0
mismatch_frame_count = 0
squat_count = 0 
is_squatting = False
warned_low_depth = False
not_deep_squat = 0
result_save_image_dir = "frames"
front_result_output_video_path = "front_result.mp4"
right_result_output_video_path = "right_result.mp4"
knee_angle_history = []
streaming_flags = {0: False, 1: False}
shared_silhouette_idx = None  # âœ… front â†’ right ë¡œ ì „ë‹¬ë  ì‹¤ë£¨ì—£ ì¸ë±ìŠ¤
last_squat_time = 0
ANGLE_CHANGE_THRESHOLD = 5
direction = "up"
squat_started = False
accuracy_result = {
    "st_accuracy": None,
    "ht_accuracy": None,
    "kd_accuracy": None
}
# ------------------- í¬ì¦ˆ ë¶„ì„ í•¨ìˆ˜ -------------------

#ì‹œì—°ìš© í´ë” ì‚­ì œ í•¨ìˆ˜
def clear_folders(*folders):
    """
    ì§€ì •ëœ í´ë”ì˜ ëª¨ë“  íŒŒì¼ì„ ì‚­ì œí•©ë‹ˆë‹¤.
    í´ë” ìì²´ëŠ” ìœ ì§€ë©ë‹ˆë‹¤.
    
    Args:
        *folders: ì‚­ì œí•  íŒŒì¼ì´ ìˆëŠ” í´ë” ê²½ë¡œë“¤
    """
    for folder in folders:
        if os.path.exists(folder):
            for file_name in os.listdir(folder):
                file_path = os.path.join(folder, file_name)
                try:
                    if os.path.isfile(file_path) or os.path.islink(file_path):
                        os.unlink(file_path)  # íŒŒì¼ ë˜ëŠ” ì‹¬ë³¼ë¦­ ë§í¬ ì‚­ì œ
                    elif os.path.isdir(file_path):
                        os.rmdir(file_path)  # ë¹ˆ ë””ë ‰í† ë¦¬ ì‚­ì œ
                except Exception as e:
                    print(f"âŒ [ERROR] íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {file_path}, {e}")
            print(f"âœ… [INFO] í´ë” ì •ë¦¬ ì™„ë£Œ: {folder}")
        else:
            print(f"âš ï¸ [WARNING] í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {folder}")

# ë‹¤ë¦¬ ê°ë„ ê³„ì‚° í•¨ìˆ˜
def calculate_angle_knee(a, b, c):
    """ì„¸ ì ì„ ì´ìš©í•´ ë¬´ë¦ ê°ë„ë¥¼ ê³„ì‚°"""
    vector_ab = np.array([a[0] - b[0], a[1] - b[1]])  # ë²¡í„° a -> b
    vector_bc = np.array([c[0] - b[0], c[1] - b[1]])  # ë²¡í„° b -> c
    dot_product = np.dot(vector_ab, vector_bc)
    magnitude_ab = np.linalg.norm(vector_ab)
    magnitude_bc = np.linalg.norm(vector_bc)
    cos_angle = dot_product / (magnitude_ab * magnitude_bc)
    angle = np.degrees(np.arccos(np.clip(cos_angle, -1.0, 1.0)))
    return angle

# ê³¨ë°˜ ê¸°ìš¸ê¸° ê³„ì‚° í•¨ìˆ˜
def calculate_tilt_hip(hip_left, hip_right):
    hip_vect = np.array([hip_right[0] - hip_left[0], hip_right[1]-hip_left[1]])
    ground_vect = np.array([1, 0])  # ì§€ë©´ ê¸°ì¤€ ë²¡í„°
    dot_product_hip = np.dot(hip_vect, ground_vect)
    magnitude_hip_vect = np.linalg.norm(hip_vect)
    cos_hip = dot_product_hip / magnitude_hip_vect
    angle_hip = np.degrees(np.arccos(np.clip(cos_hip, -1.0, 1.0)))
    return angle_hip

# ì–´ê¹¨ ê¸°ìš¸ê¸° ê³„ì‚° í•¨ìˆ˜
def calculate_tilt_shoulder(shoulder_left, shoulder_right):
    """ì–´ê¹¨ì˜ ê¸°ìš¸ê¸° ê°ë„ë¥¼ ê³„ì‚°"""
    shoulder_vect = np.array([shoulder_right[0] - shoulder_left[0], shoulder_right[1] - shoulder_left[1]])
    ground_vect = np.array([1, 0])  # ì§€ë©´ ê¸°ì¤€ ë²¡í„°
    dot_product_shoulder = np.dot(shoulder_vect, ground_vect)
    magnitude_shoulder_vect = np.linalg.norm(shoulder_vect)
    cos_shoulder = dot_product_shoulder / magnitude_shoulder_vect
    angle_shoulder = np.degrees(np.arccos(np.clip(cos_shoulder, -1.0, 1.0)))
    return angle_shoulder

# ë¬´ë¦ ê±°ë¦¬ ê³„ì‚° í•¨ìˆ˜
def calculate_knee_dis(knee_left, knee_right):
    dis_knee = np.abs(knee_left[0] - knee_right[0])
    return dis_knee

# ì–´ê¹¨ ê±°ë¦¬ ê³„ì‚° í•¨ìˆ˜
def calculate_shoulder_dis(shoulder_left, shoulder_right):
    dis_shoulder= np.abs(shoulder_left[0] - shoulder_right[0])
    return dis_shoulder        
        
# ------------------- ëª¨ë²”ìì„¸ ì €ì¥ ìë£Œ ìƒì„±  -------------------

def recording_pose(front_camera, right_camera):
    """5ì´ˆ ë™ì•ˆ í”„ë ˆì„ì„ ì €ì¥"""
    front_frame_count = 0
    right_frame_count = 0
    recording_start_time = time.time()
    frame_index = 0  # ì „ì²´ í”„ë ˆì„ ì¸ë±ìŠ¤
    
    while time.time() - recording_start_time < 5:  # 5ì´ˆ ë™ì•ˆ ë…¹í™”
        ret_front, front_frame = front_camera.read()
        ret_right, right_frame = right_camera.read()
        if not ret_front or not ret_right:
            print("âš ï¸ [WARNING] ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê³„ì† ì‹œë„ ì¤‘...")
            time.sleep(0.1)
            continue
        
        if front_frame is None or right_frame is None:
            print("âš ï¸ [WARNING] ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê³„ì† ì‹œë„ ì¤‘...")
            time.sleep(0.1)  # ì ì‹œ ëŒ€ê¸° í›„ ë‹¤ì‹œ ì‹œë„
            continue
        if frame_index % 2 == 0:
            front_frame_filename = os.path.join(front_save_image_dir, f"{front_frame_count:04d}.png")
            right_frame_filename = os.path.join(right_save_image_dir, f"{right_frame_count:04d}.png")
            cv2.imwrite(front_frame_filename, front_frame)  # ì´ë¯¸ì§€ ì €ì¥
            cv2.imwrite(right_frame_filename, right_frame)
            front_frame_count += 1
            right_frame_count += 1
        frame_index += 1

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    print("ë…¹í™” ì™„ë£Œ. í”„ë ˆì„ ì €ì¥ ì™„ë£Œ.")


def mk_dictionary(csv_file="squat_analysis.csv"):
    global data_dict
    data_dict = {}  # CSV -> ë©”ëª¨ë¦¬ ì €ì¥ìš©
    with open(csv_file, mode="r") as file:
        reader = csv.reader(file)
        next(reader)  # í—¤ë” ê±´ë„ˆë›°ê¸°
        
        for row in reader:
            frame_file, knee_dist, shoulder_tilt, knee_angle, hip_tilt, shoulder_distance = row
            knee_dist = float(knee_dist)
            shoulder_tilt = float(shoulder_tilt)
            knee_angle = float(knee_angle)
            hip_tilt = float(hip_tilt)
            shoulder_distance = float(shoulder_distance)
            data_dict[frame_file] = (knee_dist, shoulder_tilt, knee_angle, hip_tilt, shoulder_distance)
    
    return data_dict

# ------------------- ëª¨ë²”ìì„¸ ë¶„ì„ -------------------

def analyse_pose():
    """ì €ì¥ëœ í”„ë ˆì„ì„ ë¶ˆëŸ¬ì™€ ë¬´ë¦ ê°ë„ì™€ ì–´ê¹¨ ê¸°ìš¸ê¸°ë¥¼ ë¶„ì„í•˜ê³  ê²°ê³¼ë¥¼ ì¦‰ì‹œ ì €ì¥"""
    # CSV íŒŒì¼ë¡œ ê²°ê³¼ ì €ì¥
    with open("squat_analysis.csv", mode="w", newline='') as file:
        writer = csv.writer(file)
        writer.writerow(["Frame File", "Knee Distance", "Shoulder Tilt", "Knee Angle","Hip Tilt"])  # CSV í—¤ë”

        front_frame_files = sorted(os.listdir(front_save_image_dir))  # ì •ë ¬í•˜ì—¬ ìˆœì„œëŒ€ë¡œ ë¶„ì„

        for frame_file in front_frame_files:
            frame_path = os.path.join(front_save_image_dir, frame_file)
            frame = cv2.imread(frame_path)

            if frame is None:
                continue

            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = pose.process(rgb_frame)

            if results.pose_landmarks:
                landmarks = results.pose_landmarks.landmark

                # ì¢Œí‘œ ì¶”ì¶œ
                hip_left = (landmarks[mp_pose.PoseLandmark.LEFT_HIP].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP].y)
                hip_right = (landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y)
                knee_left = (landmarks[mp_pose.PoseLandmark.LEFT_KNEE].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE].y)
                knee_right = (landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].x, landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].y)
                ankle_left = (landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].x, landmarks[mp_pose.PoseLandmark.LEFT_ANKLE].y)
                shoulder_left = (landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y)
                shoulder_right = (landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].y)

                # ê°ë„ ê³„ì‚°
                knee_angle = calculate_angle_knee(hip_left, knee_left, ankle_left)
                shoulder_tilt = calculate_tilt_shoulder(shoulder_left, shoulder_right)
                knee_distance = calculate_knee_dis(knee_left, knee_right)
                hip_tilt = calculate_tilt_hip(hip_left, hip_right)
                shoulder_distance = calculate_shoulder_dis(shoulder_right, shoulder_left)
                # ë¶„ì„ ê²°ê³¼ë¥¼ CSVì— ì €ì¥
                writer.writerow([frame_file, knee_distance, shoulder_tilt, knee_angle, hip_tilt,shoulder_distance])
                print(f"{frame_file}: Knee Distance = {knee_distance:.2f}, Shoulder Tilt = {shoulder_tilt:.2f}, Knee_angle = {knee_angle:.2f}, Hip_Tilt = {hip_tilt:.2f}, Shoulder_Distance = {shoulder_distance:.2f}")
                

    print("ê°ë„ ë¶„ì„ ì™„ë£Œ. ê²°ê³¼ ì €ì¥ë¨: squat_analysis.csv")
    
def control_squat_posture(data_dict):
    not_deep_squat = False
    st_failed_front_frame_num = [] # ìì„¸ê°€ ì˜ëª»ëœ frame ì €ì¥ìš©
    ht_failed_front_frame_num = []
    kd_failed_front_frame_num = []
    min_knee_angle = min(value[2] for value in data_dict.values())
    min_angle_frame = min(data_dict, key=lambda k: data_dict[k][2])
    print(f"frame-{min_angle_frame} has min_angle: {min_knee_angle:.2f}")
    
    max_shoulder_distance = max(value[4] for value in data_dict.values())
    print(f"{max_shoulder_distance}")
    half_shoulder_distance = 0.5*max_shoulder_distance
    print(f"{half_shoulder_distance}")

    # ìŠ¤ì¿¼íŠ¸ ê°ë„ 
    if min_knee_angle > 80:
        print("Not Deep Squat")
        not_deep_squat = True
        
    # ê¸°íƒ€ ê°ë„ ì—°ì‚° 
    for frame_file, (knee_dist, shoulder_tilt, knee_angle, hip_tilt,shoulder_distance) in data_dict.items():
        #ì–´ê¹¨ ë¶ˆê· í˜•ì„ ë°”ë¡œ ê³ ì§€í•¨
        if shoulder_tilt < 177:
            print("Shoulder Tilted")
            st_failed_front_frame_num.append(frame_file) #ìì„¸ê°€ ì˜ëª»ëœ í”„ë ˆì„ ë²ˆí˜¸ ì €ì¥
            
        if hip_tilt < 177:
            print("Hip Tilted")
            ht_failed_front_frame_num.append(frame_file) #ìì„¸ê°€ ì˜ëª»ëœ í”„ë ˆì„ ë²ˆí˜¸ ì €ì¥
         
        if knee_dist > 1.2*max_shoulder_distance:
            print("Knee So Far")
            kd_failed_front_frame_num.append(frame_file) #ìì„¸ê°€ ì˜ëª»ëœ í”„ë ˆì„ ë²ˆí˜¸ ì €ì¥  
            
        if knee_dist < half_shoulder_distance:
            print("Knee So Close")
            kd_failed_front_frame_num.append(frame_file) #ìì„¸ê°€ ì˜ëª»ëœ í”„ë ˆì„ ë²ˆí˜¸ ì €ì¥
            
    #failed_front_frame_num = list(set(failed_front_frame_num))        
    
    unique_st_failed_front_frame_num = list(dict.fromkeys(st_failed_front_frame_num))
    unique_ht_failed_front_frame_num = list(dict.fromkeys(ht_failed_front_frame_num))
    unique_kd_failed_front_frame_num = list(dict.fromkeys(kd_failed_front_frame_num))
    print(f"{unique_st_failed_front_frame_num}") #ë¦¬ìŠ¤íŠ¸ í™•ì¸ìš©
    print(f"{unique_ht_failed_front_frame_num}") #ë¦¬ìŠ¤íŠ¸ í™•ì¸ìš©
    print(f"{unique_kd_failed_front_frame_num}") #ë¦¬ìŠ¤íŠ¸ í™•ì¸ìš©
    
    
    
    
    return (unique_st_failed_front_frame_num, 
            unique_ht_failed_front_frame_num, 
            unique_kd_failed_front_frame_num, 
            min_angle_frame
            )

def show_result(unique_st_failed_front_frame_num, unique_ht_failed_front_frame_num, unique_kd_failed_front_frame_num, min_angle_frame):
    global accuracy_result
    front_frame_files = sorted(os.listdir(front_save_image_dir))  # ì •ë ¬í•˜ì—¬ ìˆœì„œëŒ€ë¡œ ì¬ìƒ
    right_frame_files = sorted(os.listdir(right_save_image_dir))
    
    st_length = len(unique_st_failed_front_frame_num)
    ht_length = len(unique_ht_failed_front_frame_num)
    kd_length = len(unique_kd_failed_front_frame_num)
    
    total_frames = len(front_frame_files)  # ì´ í”„ë ˆì„ ìˆ˜
    
    st_accuracy = (total_frames - st_length) / total_frames * 100
    ht_accuracy = (total_frames - ht_length) / total_frames * 100
    kd_accuracy = (total_frames - kd_length) / total_frames * 100
    
    accuracy_result["st_accuracy"] = st_accuracy
    accuracy_result["ht_accuracy"] = ht_accuracy
    accuracy_result["kd_accuracy"] = kd_accuracy
    # ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
    result_save_dir = "static"
    os.makedirs(result_save_dir, exist_ok=True)
    
    # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„± (FFmpeg ì…ë ¥ìš©)
    temp_front_dir = os.path.join(result_save_dir, "temp_front")
    temp_right_dir = os.path.join(result_save_dir, "temp_right")
    os.makedirs(temp_front_dir, exist_ok=True)
    os.makedirs(temp_right_dir, exist_ok=True)

    # í”„ë ˆì„ ì²˜ë¦¬ ë° ì €ì¥
    for i, frame_file in enumerate(front_frame_files):
        front_frame_path = os.path.join(front_save_image_dir, frame_file)
        right_frame_path = os.path.join(right_save_image_dir, frame_file)
        front_frame = cv2.imread(front_frame_path)
        right_frame = cv2.imread(right_frame_path)

        if front_frame is None or right_frame is None:
            print(f"âš ï¸ [WARNING] Frame {frame_file} is None. Skipping...")
            continue

        # ğŸ”¹ í‹€ë¦° í”„ë ˆì„ ê°•ì¡° ë° ëœë“œë§ˆí¬ í‘œì‹œ
        rgb_front_frame = cv2.cvtColor(front_frame, cv2.COLOR_BGR2RGB)
        front_results = pose.process(rgb_front_frame)
        rgb_right_frame = cv2.cvtColor(right_frame, cv2.COLOR_BGR2RGB)
        right_results = pose.process(rgb_right_frame)
        
        if front_results.pose_landmarks:
            landmarks = front_results.pose_landmarks.landmark
            front_height, front_width, _ = front_frame.shape

            # ëœë“œë§ˆí¬ ì¢Œí‘œ ê³„ì‚°
            shoulder_left = (int(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x * front_width),
                             int(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y * front_height))
            shoulder_right = (int(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * front_width),
                              int(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * front_height))
            hip_left = (int(landmarks[mp_pose.PoseLandmark.LEFT_HIP].x * front_width),
                        int(landmarks[mp_pose.PoseLandmark.LEFT_HIP].y * front_height))
            hip_right = (int(landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x * front_width),
                         int(landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y * front_height))
            knee_left = (int(landmarks[mp_pose.PoseLandmark.LEFT_KNEE].x * front_width),
                         int(landmarks[mp_pose.PoseLandmark.LEFT_KNEE].y * front_height))
            knee_right = (int(landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].x * front_width),
                          int(landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].y * front_height))
            

            # í‹€ë¦° í”„ë ˆì„ ê°•ì¡°
            if frame_file in unique_st_failed_front_frame_num:
                cv2.line(front_frame, shoulder_left, shoulder_right, (0, 0, 255), 3)  # ì–´ê¹¨ ë¹¨ê°„ì„ 
            if frame_file in unique_ht_failed_front_frame_num:
                cv2.line(front_frame, hip_left, hip_right, (0, 0, 255), 3)  # ê³¨ë°˜ ë¹¨ê°„ì„ 
            if frame_file in unique_kd_failed_front_frame_num:
                cv2.line(front_frame, knee_left, knee_right, (0, 0, 255), 3)  # ë¬´ë¦ ë¹¨ê°„ì„ 
        # ì„ì‹œ ë””ë ‰í† ë¦¬ì— í”„ë ˆì„ ì €ì¥
        front_temp_path = os.path.join(temp_front_dir, f"{i:04d}.png")
        right_temp_path = os.path.join(temp_right_dir, f"{i:04d}.png")
        cv2.imwrite(front_temp_path, front_frame)
        cv2.imwrite(right_temp_path, right_frame)

    # FFmpeg ëª…ë ¹ì–´ë¡œ MP4 íŒŒì¼ ìƒì„±
    front_result_output_video_path = os.path.join(result_save_dir, "front_result.mp4")
    right_result_output_video_path = os.path.join(result_save_dir, "right_result.mp4")

    ffmpeg_front_command = [
        "ffmpeg", "-y", "-framerate", "20", "-i", os.path.join(temp_front_dir, "%04d.png"),
        "-c:v", "libx264", "-pix_fmt", "yuv420p", front_result_output_video_path
    ]
    ffmpeg_right_command = [
        "ffmpeg", "-y", "-framerate", "20", "-i", os.path.join(temp_right_dir, "%04d.png"),
        "-c:v", "libx264", "-pix_fmt", "yuv420p", right_result_output_video_path
    ]

    # FFmpeg ì‹¤í–‰
    subprocess.run(ffmpeg_front_command, check=True)
    subprocess.run(ffmpeg_right_command, check=True)

    # ì„ì‹œ ë””ë ‰í† ë¦¬ ì‚­ì œ
    for temp_dir in [temp_front_dir, temp_right_dir]:
        for file_name in os.listdir(temp_dir):
            os.remove(os.path.join(temp_dir, file_name))
        os.rmdir(temp_dir)

    print(f"âœ… [INFO] ê²°ê³¼ ë™ì˜ìƒ ì €ì¥ ì™„ë£Œ: {front_result_output_video_path}, {right_result_output_video_path}")
    print(f"ì •í™•ë„ í™•ì¸ìš© ë¡œê·¸:{st_accuracy},{ht_accuracy}, {kd_accuracy}")
    return st_accuracy, ht_accuracy, kd_accuracy

# ------------------- ëª¨ë²”ìì„¸ ì‹¤ë£¨ì—£ ìƒì„±  -------------------
def save_part_contour(points, height, width, part_path):
    mask = np.zeros((height, width), dtype=np.uint8)
    for x, y in points:
        if 0 <= x < width and 0 <= y < height:
            mask[y, x] = 255
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if contours:
        largest = max(contours, key=cv2.contourArea)
        np.save(part_path, largest.squeeze(axis=1))  # (N,2) í˜•íƒœ
        
def generate_silhouette(input_dir, output_dir, segment, pose, body_parts, colors):
    os.makedirs(output_dir, exist_ok=True)
    image_files = sorted(os.listdir(input_dir))

    for img_name in image_files:
        img_path = os.path.join(input_dir, img_name)
        frame = cv2.imread(img_path)
        if frame is None:
            continue

        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results_segmentation = segment.process(frame_rgb)
        results_pose = pose.process(frame_rgb)

        if not results_pose.pose_landmarks:
            print(f"âš ï¸ [WARNING] ëœë“œë§ˆí¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {img_name}")
            silhouette_frame = np.zeros_like(frame)
            output_path = os.path.join(output_dir, img_name)
            cv2.imwrite(output_path, silhouette_frame)
            continue

        landmarks = results_pose.pose_landmarks.landmark
        height, width, _ = frame.shape
        landmark_points = {
            idx: (int(landmark.x * width), int(landmark.y * height))
            for idx, landmark in enumerate(landmarks) if landmark.visibility > 0.5
        }

        mask = results_segmentation.segmentation_mask
        _, binary_mask = cv2.threshold(mask, 0.5, 255, cv2.THRESH_BINARY)
        binary_mask = binary_mask.astype(np.uint8)

        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))
        binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)

        binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)
        
        contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
##
        silhouette_frame = np.zeros_like(frame)
        cv2.drawContours(silhouette_frame, contours, -1, (255, 0, 0), thickness=5)  # ë¹¨ê°„ìƒ‰ ì™¸ê³½ì„ 
        
        assignments = {part: [] for part in body_parts}

        for contour in contours:
            if contour.ndim == 3 and contour.shape[2] == 2:
                contour = contour.squeeze(axis=1)
            elif contour.ndim != 2 or contour.shape[1] != 2:
                print(f"âš ï¸ [WARNING] ì˜ëª»ëœ ì»¨íˆ¬ì–´ í˜•ì‹: {contour.shape}")
                continue

            for pt in contour:
                min_dist = float('inf')
                closest_part = None
                for part, indices in body_parts.items():
                    for idx in indices:
                        if idx in landmark_points:
                            dist = np.linalg.norm(np.array(pt) - np.array(landmark_points[idx]))
                            if dist < min_dist:
                                min_dist = dist
                                closest_part = part
                if closest_part:
                    assignments[closest_part].append(tuple(pt))

        for part, points in assignments.items():
            for pt in points:
                cv2.circle(silhouette_frame, pt, 3, colors[part], -1)
        
        base_name = os.path.splitext(img_name)[0]
        for part, points in assignments.items():
            if not points:
                continue
            part_path = os.path.join(output_dir, f"{base_name}_{part}.npy")
            save_part_contour(points, height, width, part_path)
            np.save(part_path, np.array(points))
            
        output_path = os.path.join(output_dir, img_name)
        cv2.imwrite(output_path, silhouette_frame)
        
    print(f"âœ… [INFO] ì‹¤ë£¨ì—£ {len(image_files)}ê°œë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

def create_silhouettes(front_input_dir, right_input_dir, front_silhouette_dir, right_silhouette_dir):
    mp_selfie_segmentation = mp.solutions.selfie_segmentation
    segment = mp_selfie_segmentation.SelfieSegmentation(model_selection=1)

    mp_pose = mp.solutions.pose
    pose = mp_pose.Pose(
        static_image_mode=True,
        model_complexity=2,
        enable_segmentation=False,
        min_detection_confidence=0.5
    )

    body_parts = {
        "head": [0],
        "left_arm": [11, 13, 15],
        "right_arm": [12, 14, 16],
        "left_leg": [23, 25, 27],
        "right_leg": [24, 26, 28]
        #"torso": [11, 12, 23, 24]
    }

    colors = {
        "head": (255, 0, 0),
        "left_arm": (255, 0, 0),
        "right_arm": (255, 0, 0),
        "left_leg": (255, 0, 0),
        "right_leg": (255, 0, 0)
        #"torso": (255, 0, 0)
    }

    # Generate front and right silhouettes
    generate_silhouette(front_input_dir, front_silhouette_dir, segment, pose, body_parts, colors)
    generate_silhouette(right_input_dir, right_silhouette_dir, segment, pose, body_parts, colors)


# ------------------- ì‹¤ì‹œê°„ ì‹¤ë£¨ì—£ ì˜¤ë²„ë ˆì´  -------------------

def cache_silhouette_npy_with_angle_and_direction(silhouette_dir, body_parts, data_dict):
    cache = {}
    frame_indices = set()
    for fname in os.listdir(silhouette_dir):
        if fname.endswith('.npy'):
            idx = fname.split('_')[0]
            frame_indices.add(idx)
    for idx in frame_indices:
        cache[idx] = {}
        for part in body_parts:
            npy_path = os.path.join(silhouette_dir, f"{idx}_{part}.npy")
            if os.path.exists(npy_path):
                cache[idx][part] = np.load(npy_path)
            else:
                cache[idx][part] = np.array([])
        # ì¶”ê°€: ê°ë„/ë°©í–¥ ì •ë³´ ì €ì¥
        # data_dictì˜ keyëŠ” "0000.png" í˜•íƒœì¼ ìˆ˜ ìˆìœ¼ë‹ˆ idx+".png"ë¡œ ì ‘ê·¼
        frame_file = f"{idx}.png"
        if frame_file in data_dict:
            knee_angle = data_dict[frame_file][2]
            # ë™ì‘ ë°©í–¥ ì¶”ì • (ì´ì „ í”„ë ˆì„ê³¼ ë¹„êµ)
            prev_idx = f"{int(idx)-1:04d}"
            if f"{prev_idx}.png" in data_dict:
                prev_angle = data_dict[f"{prev_idx}.png"][2]
                direction = "down" if knee_angle < prev_angle else "up"
            else:
                direction = "down"
            cache[idx]["knee_angle"] = knee_angle
            cache[idx]["direction"] = direction
    return cache

# ì„œë²„ ì‹œì‘ ì‹œ ìºì‹±
#data_dict = mk_dictionary()
#front_silhouette_cache = cache_silhouette_npy_with_angle_and_direction(front_silhouette_dir, ["head","left_arm","right_arm","left_leg","right_leg"], data_dict)
#right_silhouette_cache = cache_silhouette_npy_with_angle_and_direction(right_silhouette_dir, ["head","left_arm","right_arm","left_leg","right_leg"], data_dict)

def realtime_synchronize(camera_type, data_dict, front_camera, right_camera, reps=1, sets=3, current_set=1):
    print("ğŸ”µ [INFO] ì‹¤ë£¨ì—£ ë™ê¸°í™” ì‹œì‘")
    global squat_count, not_deep_squat, shared_silhouette_idx
    #squat_count = 0
    silhouette_angle_list = np.array([value[2] for value in data_dict.values()])
    silhouette_keys = list(data_dict.keys())

    colors = {
        "head": (255, 0, 0),
        "left_arm": (255, 0, 0),
        "right_arm": (255, 0, 0),
        "left_leg": (255, 0, 0),
        "right_leg": (255, 0, 0)
    }
    body_parts = {
        "head": [0],
        "left_arm": [11, 13, 15],
        "right_arm": [12, 14, 16],
        "left_leg": [23, 25, 27],
        "right_leg": [24, 26, 28]
    }

    mp_pose = mp.solutions.pose
    pose_front = mp_pose.Pose(static_image_mode=False, model_complexity=0, smooth_landmarks=True,
                              min_detection_confidence=0.3, min_tracking_confidence=0.3)
    pose_right = mp_pose.Pose(static_image_mode=False, model_complexity=0, smooth_landmarks=True,
                              min_detection_confidence=0.3, min_tracking_confidence=0.3)

    previous_knee_angle = None
    previous_silhouette_idx = None
    direction = "down"
    frame_counter = 0  

    while True:
        try:
            ret_front, front_frame = front_camera.read()
            ret_right, right_frame = right_camera.read()
            if not ret_front or front_frame is None or not ret_right or right_frame is None:
                time.sleep(0.01)
                continue
            
            frame_counter += 1
            if frame_counter % 2 != 0:
                continue

            # FRONT ì²˜ë¦¬ ë° ì‹¤ë£¨ì—£ ì¸ë±ìŠ¤ ê²°ì •
            def process_front():
                nonlocal previous_knee_angle, previous_silhouette_idx, direction
                global shared_silhouette_idx
                frame_rgb = cv2.cvtColor(front_frame, cv2.COLOR_BGR2RGB)
                results = pose_front.process(frame_rgb)
                if not results.pose_landmarks:
                    return front_frame, previous_knee_angle, shared_silhouette_idx

                landmarks = results.pose_landmarks.landmark
                width, height = front_frame.shape[1], front_frame.shape[0]
                hip = (landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x * width, landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y * height)
                knee = (landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].x * width, landmarks[mp_pose.PoseLandmark.RIGHT_KNEE].y * height)
                ankle = (landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE].x * width, landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE].y * height)
                knee_angle = calculate_angle_knee(hip, knee, ankle)

                if previous_knee_angle is None or abs(knee_angle - previous_knee_angle) > ANGLE_CHANGE_THRESHOLD:
                    idx = np.argmin(np.abs(silhouette_angle_list - knee_angle))
                    silhouette_idx = os.path.splitext(silhouette_keys[idx])[0]

                    previous_knee_angle = knee_angle
                    previous_silhouette_idx = silhouette_idx
                    shared_silhouette_idx = silhouette_idx
                else:
                    silhouette_idx = previous_silhouette_idx
                
                silhouette = front_silhouette_cache.get(silhouette_idx, {})
                overlay = draw_silhouette_overlay(front_frame, silhouette, body_parts, colors, results)

                # ë””ë²„ê·¸ í‘œì‹œ
                cv2.putText(overlay, f"Silhouette: {silhouette_idx}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 0), 2)

                # ìŠ¤ì¿¼íŠ¸ ì¹´ìš´íŒ…
                update_squat_count(knee_angle)
                return overlay, knee_angle, silhouette_idx

            def process_right():
                silhouette = right_silhouette_cache.get(shared_silhouette_idx, {})
                frame_rgb = cv2.cvtColor(right_frame, cv2.COLOR_BGR2RGB)
                results = pose_right.process(frame_rgb)
                overlay = draw_silhouette_overlay(right_frame, silhouette, body_parts, colors, results)
                cv2.putText(overlay, f"Silhouette: {shared_silhouette_idx}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 255), 2)
                return overlay

            # ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰
            future_front = executor.submit(process_front)
            future_right = executor.submit(process_right)
            processed_front, _, _ = future_front.result()
            processed_right = future_right.result()

            # ì¢…ë£Œ ì¡°ê±´
            if squat_count >= reps:
                
                total = squat_count + not_deep_squat
                accuracy = squat_count / total * 100 if total > 0 else 0
                print(f"âœ… [INFO] ì„¸íŠ¸ ì™„ë£Œ - ì •í™•ë„: {accuracy:.1f}%")
                #squat_count = 0
                not_deep_squat = 0
                time.sleep(3) # 3ì´ˆ ëŒ€ê¸° í›„ breaktime.htmlë¡œ ì´ë™
                break

            # ê²°ê³¼ ì†¡ì¶œ
            frame = processed_front if camera_type == "front" else processed_right
            _, buffer = cv2.imencode('.jpg', frame)
            yield (b'--frame\r\nContent-Type: image/jpeg\r\n\r\n' + buffer.tobytes() + b'\r\n')

        except Exception as e:
            import traceback
            print(f"âŒ [ERROR] ì‹¤ì‹œê°„ ë™ê¸°í™” ì˜¤ë¥˜: {e}")
            traceback.print_exc()
            time.sleep(0.01)
            continue


# ë„ìš°ë¯¸ í•¨ìˆ˜ë“¤
def draw_silhouette_overlay(frame, silhouette, body_parts, colors, results):
    overlay = frame.copy()
    height, width = frame.shape[:2]
    if not results.pose_landmarks:
        return overlay
    landmarks = results.pose_landmarks.landmark
    mismatch_parts = []
    
    for part, indices in body_parts.items():
        part_pixels = silhouette.get(part, np.array([]))
        if part_pixels.shape[0] < 3:
            continue

        part_centroid = np.mean(part_pixels, axis=0) if len(part_pixels) > 0 else None
        landmark_centroid = np.mean([(landmarks[i].x * width, landmarks[i].y * height) for i in indices], axis=0)
        landmark_centroid = np.mean([(landmarks[i].x * width, landmarks[i].y * height) for i in indices], axis=0)
        dist = np.linalg.norm(part_centroid - landmark_centroid)
        color = (0,0,255) if dist > 80 else colors[part]
        pts = part_pixels.reshape(-1,1,2).astype(np.int32)
        cv2.polylines(overlay, [pts], isClosed=True, color=color, thickness=3)
        return overlay

def update_squat_count(knee_angle):
    global squat_count, is_squatting, warned_low_depth, not_deep_squat, direction , squat_started
    squat_down_threshold = 110  # ë‚´ë ¤ê°”ë‹¤ê³  íŒë‹¨í•˜ëŠ” ê°ë„
    squat_up_threshold = 160    # ì™„ì „íˆ ì˜¬ë¼ì™”ë‹¤ê³  íŒë‹¨í•˜ëŠ” ê°ë„
    deep_squat_limit = 99       # ì¶©ë¶„íˆ ê¹Šê²Œ ë‚´ë ¤ê°”ëŠ”ì§€ íŒë‹¨
    
    if direction == "up" and knee_angle < squat_down_threshold:
        direction = "down"
        squat_started = True
        # print("â¬‡ï¸ ë‚´ë ¤ê° ê°ì§€")

    elif direction == "down" and knee_angle > squat_up_threshold:
        direction = "up"
        if squat_started:
            if knee_angle < deep_squat_limit:
                not_deep_squat += 1
                print("âš ï¸ ê¹Šì§€ ì•Šì€ ìŠ¤ì¿¼íŠ¸")
            else:
                squat_count += 1
                print(f"âœ… ìŠ¤ì¿¼íŠ¸ ì¹´ìš´íŠ¸: {squat_count}")
            squat_started = False  # ë‹¤ìŒ ì‚¬ì´í´ë¡œ ë¦¬ì…‹
    squat_count_status["count"] = squat_count

# ------------------- Flask ì•± ì´ˆê¸°í™” -------------------

app = Flask(__name__, static_folder='static')
app.secret_key = 'your-very-secret-key-1234'  # ì„¸ì…˜ ì‚¬ìš©ì„ ìœ„í•œ ì‹œí¬ë¦¿í‚¤ ì„¤ì •


# ------------------- Flask ë¼ìš°íŠ¸ -------------------
def generate_stream(camera):
    def generate():
        while True:
            ret, frame = camera.read()
            if not ret or frame is None:
                print("âš ï¸ [WARNING] í”„ë ˆì„ì´ Noneì…ë‹ˆë‹¤. ê³„ì† ì‹œë„ ì¤‘...")
                time.sleep(0.1)
                continue
            _, buffer = cv2.imencode('.jpg', frame)
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + buffer.tobytes() + b'\r\n')
    return generate

@app.route('/video_feed/front')
def video_feed_front():
    """
    ì „ë©´ ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ì„ ì œê³µí•˜ëŠ” ë¼ìš°íŠ¸.
    """
    return Response(generate_stream(front_camera)(),
                    mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/video_feed/right')
def video_feed_right():
    """
    ì „ë©´ ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ì„ ì œê³µí•˜ëŠ” ë¼ìš°íŠ¸.
    """
    return Response(generate_stream(right_camera)(),
                    mimetype='multipart/x-mixed-replace; boundary=frame')
    
@app.route('/')
def index():
    return render_template('index.html')
    

@app.route('/squat_ex2')
def squat_ex2():
    exercise = request.args.get('exercise', 'default_exercise')
    return render_template('squat_ex2.html', exercise=exercise)

@app.route('/squat_guide3')
def squat_guide3():
    # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹œì‘
    thread = Thread(target=process_squat_analysis, args=(front_camera, right_camera))
    thread.start()
    # ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¼ í˜ì´ì§€ ë Œë”ë§
    return render_template('squat_guide3.html')

pose_analyse_complete = False
silhouette_creation_complete = False
def process_squat_analysis(front_camera, right_camera):
    """
    ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìŠ¤ì¿¼íŠ¸ ë¶„ì„ ì‘ì—…ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜.
    """
    global silhouette_creation_complete
    global pose_analyse_complete
    # 1. í”„ë ˆì„ ì €ì¥
    time.sleep(4) # Nì´ˆ ì¹´ìš´íŠ¸
    recording_pose(front_camera, right_camera)
    
    def run_pose_analyse():
        global pose_analyse_complete
        analyse_pose()
        data_dict = mk_dictionary()
        st_failed, ht_failed, kd_failed, min_angle_frame = control_squat_posture(data_dict)
        st_accuracy, ht_accuracy, kd_accuracy = show_result(st_failed, ht_failed, kd_failed, min_angle_frame)
        mean_accuracy = round((st_accuracy + ht_accuracy + kd_accuracy) / 3, 1)
        session['mean_accuracy'] = mean_accuracy
        print("âœ… [INFO] ë¶„ì„ ì‘ì—… ì™„ë£Œ. squat_check4.htmlë¡œ ì´ë™í•©ë‹ˆë‹¤.")
        pose_analyse_complete = True

    def run_create_silhouettes():
        global silhouette_creation_complete
        create_silhouettes(front_save_image_dir, right_save_image_dir, front_silhouette_dir, right_silhouette_dir)
        silhouette_creation_complete = True
        print("âœ… [INFO] ì‹¤ë£¨ì—£ ìƒì„± ì™„ë£Œ.")
        global front_silhouette_cache, right_silhouette_cache, data_dict
        data_dict = mk_dictionary()  # CSV ë‹¤ì‹œ ì½ê¸°
        front_silhouette_cache = cache_silhouette_npy_with_angle_and_direction(front_silhouette_dir, ["head","left_arm","right_arm","left_leg","right_leg"], data_dict)
        right_silhouette_cache = cache_silhouette_npy_with_angle_and_direction(right_silhouette_dir, ["head","left_arm","right_arm","left_leg","right_leg"], data_dict)
        print("âœ… [INFO] ì‹¤ë£¨ì—£ ìºì‹± ì™„ë£Œ.")

    Thread(target=run_create_silhouettes).start()
   
    Thread(target=run_pose_analyse).start()
    
@app.route('/loading')
def loading():
    """
    ë¡œë”© í˜ì´ì§€ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤.
    """
    return render_template('loading.html')
    
@app.route('/squat_check4')
def squat_check4():
    global accuracy_result
    return render_template('squat_check4.html',
        st_accuracy=accuracy_result["st_accuracy"],
        ht_accuracy=accuracy_result["ht_accuracy"],
        kd_accuracy=accuracy_result["kd_accuracy"])

@app.route('/setting5', methods=['GET', 'POST'])
def setting5():
    if request.method == 'POST':
        sets = int(request.form.get('sets'))
        reps = int(request.form.get('reps'))
        session['sets'] = sets
        session['reps'] = reps
        session['current_set'] = 1
        return redirect(url_for('squat_start6'))
    return render_template('setting5.html')

@app.route('/squat_start6', methods=['GET', 'POST'])
def squat_start6():
        #global squat_count       
        #squat_count = 0
        current_set = session.get('current_set', 1)
        sets = session.get('sets', 3)
        reps = session.get('reps', 10)
        return render_template('squat_start6.html', sets=sets, reps=reps, current_set=current_set)
    
 # ...existing code...

@app.route('/squat_end7')
def squat_end7():
    # show_resultì—ì„œ ì„¸ì…˜ì— ì €ì¥í•œ í‰ê·  ì •í™•ë„ ë¶ˆëŸ¬ì˜¤ê¸°
    accuracy = session.get('mean_accuracy', None)
    if accuracy is None:
        # ë§Œì•½ ì„¸ì…˜ì— ê°’ì´ ì—†ìœ¼ë©´ ì„ì‹œë¡œ ëœë¤ê°’ ì‚¬ìš© (ì˜ˆì™¸ì²˜ë¦¬)
        accuracy = round(random.uniform(60, 92), 1)

    if accuracy >= 80:
        feedback_list = [
            "ì•„ì£¼ ì˜í•˜ê³  ìˆì–´ìš”! ì–´ê¹¨ë§Œ ì¡°ê¸ˆ ë” í´ë³´ì„¸ìš”.",
            "ì¢‹ì€ ìì„¸ì…ë‹ˆë‹¤! ë¬´ë¦ ë°©í–¥ë§Œ ì¡°ê¸ˆ ì‹ ê²½ ì¨ë³´ì„¸ìš”.",
            "ê±°ì˜ ì™„ë²½í•´ìš”! í˜¸í¡ì„ ì¼ì •í•˜ê²Œ í•´ë³´ì„¸ìš”.",
            "ë©‹ì§„ ìì„¸ì˜ˆìš”! ì‹œì„ ì„ ì •ë©´ìœ¼ë¡œ ìœ ì§€í•´ë³´ì„¸ìš”.",
            "ì˜í•˜ê³  ìˆìŠµë‹ˆë‹¤! ì—‰ë©ì´ë¥¼ ì¡°ê¸ˆ ë” ë’¤ë¡œ ë¹¼ë³´ì„¸ìš”."
        ]
    else:
        feedback_list = [
            "ì¡°ê¸ˆ ë” ì§‘ì¤‘í•´ì„œ í•´ë³´ì„¸ìš”!",
            "ë” ê¹Šê²Œ ì•‰ì•„ë³´ì„¸ìš”.",
            "ìì„¸ë¥¼ í•œ ë²ˆ ë” ì ê²€í•´ë³´ì„¸ìš”.",
            "ê¾¸ì¤€íˆ ì—°ìŠµí•˜ë©´ ë” ì¢‹ì•„ì§ˆ ê±°ì˜ˆìš”.",
            "ì¡°ê¸ˆ ë” ë…¸ë ¥í•´ë´…ì‹œë‹¤!"
        ]
    feedback = random.choice(feedback_list)
    return render_template('squat_end7.html', accuracy=accuracy, feedback=feedback)

@app.route('/silhouette_status')
def silhouette_status():
    """
    ì‹¤ë£¨ì—£ ìƒì„± ìƒíƒœë¥¼ ë°˜í™˜í•˜ëŠ” API.
    """
    global silhouette_creation_complete
    return {'complete': silhouette_creation_complete}

@app.route('/pose_analyse_status')
def psoe_analyse_status():
    """
    ì‹¤ë£¨ì—£ ìƒì„± ìƒíƒœë¥¼ ë°˜í™˜í•˜ëŠ” API.
    """
    global pose_analyse_complete
    return {'complete': pose_analyse_complete}

@app.route('/start_stream/<int:camera_index>')
def start_stream(camera_index):
    """Start streaming for the specified camera index."""
    streaming_flags[camera_index] = True
    return '', 204  # Return a no-content response

@app.route('/stop_stream/<int:camera_index>')
def stop_stream(camera_index):
    """Stop streaming for the specified camera index."""
    streaming_flags[camera_index] = False
    return '', 204  # Return a no-content response

@app.route('/video_feed/overlay/front')
def video_feed_overlay_front():
    reps = int(request.args.get('reps', 10))
    sets = int(request.args.get('sets', 3))
    current_set = session.get('current_set', 1)
    return Response(realtime_synchronize("front", data_dict, front_camera, right_camera,reps,sets,current_set),
                    mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/video_feed/overlay/right')
def video_feed_overlay_right():
    reps = int(request.args.get('reps', 10))
    sets = int(request.args.get('sets', 3))
    current_set = session.get('current_set', 1)
    return Response(realtime_synchronize("right", data_dict, front_camera, right_camera,reps,sets,current_set),
                    mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/update_set', methods=['POST'])
def update_set():
    session['current_set'] = int(request.form['current_set'])
    return '', 204

@app.route('/breaktime')
def breaktime():
    global squat_count
    squat_count = 0
    current_set = session.get('current_set', 1)
    sets = session.get('sets', 3)
    # JSì—ì„œ 30ì´ˆ í›„ squat_start6ë¡œ ìë™ ì´ë™
    current_set += 1
    session["current_set"] = current_set
    if current_set > sets:
        return redirect(url_for('squat_end7'))
    return render_template('rest.html', current_set=current_set, sets=sets)

@app.route('/squat_count_status')
def squat_count_status_api():
    squat_count_status["set"] = session.get('current_set', 1)
    squat_count_status["sets"] = session.get('sets', 3)
    return jsonify(squat_count_status)

if __name__ == '__main__':
    try:
        clear_folders(front_save_image_dir, right_save_image_dir, front_silhouette_dir, right_silhouette_dir)
        # Flask ì„œë²„ ì‹¤í–‰
        app.run(host='0.0.0.0', port=5001, threaded=True)
    finally:
        # ìì› ì •ë¦¬
        front_camera.release()
        right_camera.release()
        executor.shutdown(wait=True)
